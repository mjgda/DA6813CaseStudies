---
title: "BookBinders Book Club"
group members: "Visha Arumugam, Michael Grogan,Sanyogita Apte"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(InformationValue)
library(e1071)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies")
```


```{r readprepare}
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
str(bbtrain)
str(bbtest)
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]

#view the distribution of target variable
plot(bbtrain$Choice)
```
```{r}
table(bbtrain$Choice)
```


```{r readprepare}

#balance the target classes
bbtrain<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)

#lose extraneous class variable from upsampling
#bbtrain<-bbtrain[-11]

bbtrain$Choice <- factor(bbtrain$Class, levels=rev(levels(bbtrain$Class)))
bbtrain$Class<-NULL

#bbtest$Choice <- factor(bbtest$Choice, levels=rev(levels(bbtest$Choice)))

```

```{r}
str(bbtrain)
```


```{r, echo=F}
#boruta_var_imp_output=Boruta(Choice~.,data=bbtrain,doTrace=1)
#boruta_signif <- getSelectedAttributes(boruta_var_imp_output, withTentative = TRUE)



#boruta_roug_fix_mod=TentativeRoughFix(boruta_var_imp_output)
# Variable Importance Scores#
#boruta_imps <- attStats(boruta_roug_fix_mod)
#boruta_imps2 = boruta_imps[boruta_imps$decision != 'Rejected', c('meanImp', 'decision')]
#boruta_imps2[order(-boruta_imps2$meanImp), ]

#plot(boruta_var_imp_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")  

```


```{r}

log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)



tunedsvm=tune(svm,Choice~.,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))

svm<-tunedsvm$best.model



summary(log)
summary(svm)

bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lm<-glm(Choice~.,data=bbtrain,family=gaussian)

summary(lm)
```



```{r}

predlog<-predict(log,bbtest,type="response")
predsvm<-predict(svm,bbtest)


bbtest$Choice<-as.numeric(as.character(bbtest$Choice))
predlm<-predict(lm,bbtest)



predlog<-as.factor(ifelse(predlog>0.5,0,1))
predlm<-as.factor(ifelse(predlm>0.5,1,0))

predlm<-factor(predlm,levels=rev(levels(predlm)))
predlog<-factor(predlog,levels=rev(levels(predlog)))
```

```{r echo=F}

bbtest$Choice<-as.factor(bbtest$Choice)
bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))

print(caret::confusionMatrix(predlog,bbtest$Choice))
cat("\n")

print(caret::confusionMatrix(predsvm,bbtest$Choice))
cat("\n")

print(caret::confusionMatrix(predlm,bbtest$Choice))
cat("\n")


```
```{r}
str(predlog)
str(bbtest$Choice)
```

### I - Executive Summary


```{r}
str(bbtrain)
```


### II - The Problem

The Bookbinders Book Club is a specialty book distributor that is seeking to survive in an business environment increasingly dominated by superstores like Amazon that are able to leverage economies of scale to out-compete book clubs and smaller retail stores. In order to be more competitive, BBBC has collected data on its customers and plans to use that data to identify the characteristics of the individuals that are most likely to buy a book when mailed a specialty brochure.

The data they have on their customers is primarily numeric data relating to how many books the customer has bought from different categories such as Cooking, Art, etc.

They have specified that they want to find the most useful model out of the following options: logistic regression, linear regression, and support vector machine.

We will show how we evaluated the three models and determined the top performer, and compare the profitability of using that model to determine customers to send mailers vs sending mailers to the entire customer base.


```{r}
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
```

## III - Review of Related Literature

## IV - Methodology


### V - Data




### VI - Findings


### VII - Conclusions


### Appendix

#### Preprocessing the data


#### Determining most significant variables




#### Training different models


#### Model output
