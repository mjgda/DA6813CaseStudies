#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
str(bbtrain)
str(bbtest)
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
#view the distribution of target variable
plot(bbtrain$Choice)
table(bbtrain$Choice)
#balance the target classes
bbtrain<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
#lose extraneous class variable from upsampling
#bbtrain<-bbtrain[-11]
bbtrain$Choice <- factor(bbtrain$Class, levels=rev(levels(bbtrain$Class)))
bbtrain$Class<-NULL
#bbtest$Choice <- factor(bbtest$Choice, levels=rev(levels(bbtest$Choice)))
str(bbtrain)
#boruta_var_imp_output=Boruta(Choice~.,data=bbtrain,doTrace=1)
#boruta_signif <- getSelectedAttributes(boruta_var_imp_output, withTentative = TRUE)
#boruta_roug_fix_mod=TentativeRoughFix(boruta_var_imp_output)
# Variable Importance Scores#
#boruta_imps <- attStats(boruta_roug_fix_mod)
#boruta_imps2 = boruta_imps[boruta_imps$decision != 'Rejected', c('meanImp', 'decision')]
#boruta_imps2[order(-boruta_imps2$meanImp), ]
#plot(boruta_var_imp_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
tunedsvm=tune(svm,Choice~.,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
summary(log)
summary(svm)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lm<-glm(Choice~.,data=bbtrain,family=gaussian)
summary(lm)
predlog<-predict(log,bbtest,type="response")
predsvm<-predict(svm,bbtest)
predsvm<-factor(predsvm,levels=rev(levels(predsvm)))
bbtest$Choice<-as.numeric(as.character(bbtest$Choice))
predlm<-predict(lm,bbtest)
predlog<-as.factor(ifelse(predlog>0.5,1,0))
predlm<-as.factor(ifelse(predlm>0.5,1,0))
bbtest$Choice<-as.factor(bbtest$Choice)
bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
print(caret::confusionMatrix(predlog,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlm,bbtest$Choice))
cat("\n")
str(predlog)
str(bbtest$Choice)
str(predlog)
str(bbtest$Choice)
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(InformationValue)
library(e1071)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
str(bbtrain)
str(bbtest)
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
#view the distribution of target variable
plot(bbtrain$Choice)
table(bbtrain$Choice)
#balance the target classes
bbtrain<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
#lose extraneous class variable from upsampling
#bbtrain<-bbtrain[-11]
bbtrain$Choice <- factor(bbtrain$Class, levels=rev(levels(bbtrain$Class)))
bbtrain$Class<-NULL
#bbtest$Choice <- factor(bbtest$Choice, levels=rev(levels(bbtest$Choice)))
str(bbtrain)
#boruta_var_imp_output=Boruta(Choice~.,data=bbtrain,doTrace=1)
#boruta_signif <- getSelectedAttributes(boruta_var_imp_output, withTentative = TRUE)
#boruta_roug_fix_mod=TentativeRoughFix(boruta_var_imp_output)
# Variable Importance Scores#
#boruta_imps <- attStats(boruta_roug_fix_mod)
#boruta_imps2 = boruta_imps[boruta_imps$decision != 'Rejected', c('meanImp', 'decision')]
#boruta_imps2[order(-boruta_imps2$meanImp), ]
#plot(boruta_var_imp_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
tunedsvm=tune(svm,Choice~.,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
summary(log)
summary(svm)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lm<-glm(Choice~.,data=bbtrain,family=gaussian)
summary(lm)
predlog<-predict(log,bbtest,type="response")
predsvm<-predict(svm,bbtest)
predsvm<-factor(predsvm,levels=rev(levels(predsvm)))
bbtest$Choice<-as.numeric(as.character(bbtest$Choice))
predlm<-predict(lm,bbtest)
predlog<-as.factor(ifelse(predlog>0.5,1,0))
predlm<-as.factor(ifelse(predlm>0.5,1,0))
bbtest$Choice<-as.factor(bbtest$Choice)
#bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
print(caret::confusionMatrix(predlog,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlm,bbtest$Choice))
cat("\n")
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(InformationValue)
library(e1071)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
str(bbtrain)
str(bbtest)
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
#view the distribution of target variable
plot(bbtrain$Choice)
table(bbtrain$Choice)
#balance the target classes
bbtrain<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
#lose extraneous class variable from upsampling
#bbtrain<-bbtrain[-11]
bbtrain$Choice <- factor(bbtrain$Class, levels=rev(levels(bbtrain$Class)))
bbtrain$Class<-NULL
#bbtest$Choice <- factor(bbtest$Choice, levels=rev(levels(bbtest$Choice)))
str(bbtrain)
#boruta_var_imp_output=Boruta(Choice~.,data=bbtrain,doTrace=1)
#boruta_signif <- getSelectedAttributes(boruta_var_imp_output, withTentative = TRUE)
#boruta_roug_fix_mod=TentativeRoughFix(boruta_var_imp_output)
# Variable Importance Scores#
#boruta_imps <- attStats(boruta_roug_fix_mod)
#boruta_imps2 = boruta_imps[boruta_imps$decision != 'Rejected', c('meanImp', 'decision')]
#boruta_imps2[order(-boruta_imps2$meanImp), ]
#plot(boruta_var_imp_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
tunedsvm=tune(svm,Choice~.,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
summary(log)
summary(svm)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lm<-glm(Choice~.,data=bbtrain,family=gaussian)
summary(lm)
predlog<-predict(log,bbtest,type="response")
predsvm<-predict(svm,bbtest)
predsvm<-factor(predsvm,levels=rev(levels(predsvm)))
bbtest$Choice<-as.numeric(as.character(bbtest$Choice))
predlm<-predict(lm,bbtest)
predlog<-as.factor(ifelse(predlog>0.5,0,1))
predlm<-as.factor(ifelse(predlm>0.5,1,0))
bbtest$Choice<-as.factor(bbtest$Choice)
#bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
print(caret::confusionMatrix(predlog,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlm,bbtest$Choice))
cat("\n")
str(predlog)
str(bbtest$Choice)
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(InformationValue)
library(e1071)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
str(bbtrain)
str(bbtest)
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
#view the distribution of target variable
plot(bbtrain$Choice)
table(bbtrain$Choice)
#balance the target classes
bbtrain<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
#lose extraneous class variable from upsampling
#bbtrain<-bbtrain[-11]
#bbtrain$Choice <- factor(bbtrain$Class, levels=rev(levels(bbtrain$Class)))
bbtrain$Choice<-bbtrain$Class
bbtrain$Class<-NULL
#bbtest$Choice <- factor(bbtest$Choice, levels=rev(levels(bbtest$Choice)))
str(bbtrain)
#boruta_var_imp_output=Boruta(Choice~.,data=bbtrain,doTrace=1)
#boruta_signif <- getSelectedAttributes(boruta_var_imp_output, withTentative = TRUE)
#boruta_roug_fix_mod=TentativeRoughFix(boruta_var_imp_output)
# Variable Importance Scores#
#boruta_imps <- attStats(boruta_roug_fix_mod)
#boruta_imps2 = boruta_imps[boruta_imps$decision != 'Rejected', c('meanImp', 'decision')]
#boruta_imps2[order(-boruta_imps2$meanImp), ]
#plot(boruta_var_imp_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
tunedsvm=tune(svm,Choice~.,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
summary(log)
summary(svm)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lm<-glm(Choice~.,data=bbtrain,family=gaussian)
summary(lm)
predlog<-predict(log,bbtest,type="response")
predsvm<-predict(svm,bbtest)
#predsvm<-factor(predsvm,levels=rev(levels(predsvm)))
bbtest$Choice<-as.numeric(as.character(bbtest$Choice))
predlm<-predict(lm,bbtest)
predlog<-as.factor(ifelse(predlog>0.5,0,1))
predlm<-as.factor(ifelse(predlm>0.5,1,0))
bbtest$Choice<-as.factor(bbtest$Choice)
#bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
print(caret::confusionMatrix(predlog,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlm,bbtest$Choice))
cat("\n")
predlog<-predict(log,bbtest,type="response")
predsvm<-predict(svm,bbtest)
bbtest$Choice<-as.numeric(as.character(bbtest$Choice))
predlm<-predict(lm,bbtest)
predlog<-as.factor(ifelse(predlog>0.5,0,1))
predlm<-as.factor(ifelse(predlm>0.5,1,0))
predlm<-factor(predlm,levels=rev(levels(predlm)))
predlog<-factor(predlog,levels=rev(levels(predlog)))
bbtest$Choice<-as.factor(bbtest$Choice)
bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
print(caret::confusionMatrix(predlog,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlm,bbtest$Choice))
cat("\n")
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(InformationValue)
library(e1071)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
str(bbtrain)
str(bbtest)
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
#view the distribution of target variable
plot(bbtrain$Choice)
table(bbtrain$Choice)
plot(bbtrain$Choice)
#balance the target classes
bbtrain<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
#lose extraneous class variable from upsampling
#bbtrain<-bbtrain[-11]
bbtrain$Choice <- factor(bbtrain$Class, levels=rev(levels(bbtrain$Class)))
bbtrain$Class<-NULL
#bbtest$Choice <- factor(bbtest$Choice, levels=rev(levels(bbtest$Choice)))
str(bbtrain)
plot(bbtrain$Choice)
#boruta_var_imp_output=Boruta(Choice~.,data=bbtrain,doTrace=1)
#boruta_signif <- getSelectedAttributes(boruta_var_imp_output, withTentative = TRUE)
#boruta_roug_fix_mod=TentativeRoughFix(boruta_var_imp_output)
# Variable Importance Scores#
#boruta_imps <- attStats(boruta_roug_fix_mod)
#boruta_imps2 = boruta_imps[boruta_imps$decision != 'Rejected', c('meanImp', 'decision')]
#boruta_imps2[order(-boruta_imps2$meanImp), ]
#plot(boruta_var_imp_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
tunedsvm=tune(svm,Choice~.,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
summary(log)
summary(svm)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lm<-glm(Choice~.,data=bbtrain,family=gaussian)
summary(lm)
predlog<-predict(log,bbtest,type="response")
predsvm<-predict(svm,bbtest)
bbtest$Choice<-as.numeric(as.character(bbtest$Choice))
predlm<-predict(lm,bbtest)
predlog<-as.factor(ifelse(predlog>0.5,0,1))
predlm<-as.factor(ifelse(predlm>0.5,1,0))
predlm<-factor(predlm,levels=rev(levels(predlm)))
predlog<-factor(predlog,levels=rev(levels(predlog)))
bbtest$Choice<-as.factor(bbtest$Choice)
bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
print(caret::confusionMatrix(predlog,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlm,bbtest$Choice))
cat("\n")
str(predlog)
str(bbtest$Choice)
str(bbtrain)
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
profit<-31.95-(15*1.45)
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
profit<-31.95-(15*1.45)
profit
table(bbtest$Choice)
sum(bbtest$Choice==0)
sum(bbtest$Choice)
length(bbtest$Choice)
sum(bbtest$Choice==1)/length(bbtest$Choice)
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
blanketprofit
caret::confusionMatrix(predlog,bbtest$Choice)[7]
names(caret::confusionMatrix(predlog,bbtest$Choice))
caret::confusionMatrix(predlog,bbtest$Choice)$byClass[7]
caret::confusionMatrix(predlog,bbtest$Choice)$byClass[8]
caret::confusionMatrix(predlog,bbtest$Choice)$byClass[10]
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
detectionprevalence<-caret::confusionMatrix(predlog,bbtest$Choice)$byClass[10]
detectionprevalence
str(detectionprevalence)
detectionprevalence*2
detectionprevalence
detectionprevalence*2
detectionprevalence
detectionprevalence[1]
detectionprevalence[0]
str(detectionprevalence)
as.numeric(detectionprevalence)
caret::confusionMatrix(predlog,bbtest$Choice)$byClass[6]
caret::confusionMatrix(predlog,bbtest$Choice)$byClass[7]
caret::confusionMatrix(predlog,bbtest$Choice)$byClass[8]
caret::confusionMatrix(predlog,bbtest$Choice)$byClass[5]
caret::confusionMatrix(predlog,bbtest$Choice)$byClass[4]
caret::confusionMatrix(predlog,bbtest$Choice)$byClass[3]
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
detectionprevalence<-as.numeric(caret::confusionMatrix(predlog,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(predlog,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
print(blanketprofit)
print(targetedprofit)
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
bestpredictor<-predlog
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-targetdprofit/blanketprofit
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
bestpredictor<-predlog
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-targetedprofit/blanketprofit
print(blanketprofit)
print(targetedprofit)
print(outperformance)
(targetdprofit-blanketprofit)/blanketprofit
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
bestpredictor<-predlog
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-targetedprofit/blanketprofit
print(blanketprofit)
print(targetedprofit)
print(outperformance)
(targetedprofit-blanketprofit)/blanketprofit
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
bestpredictor<-predlog
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(blanketprofit)
print(targetedprofit)
print(outperformance)
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
bestpredictor<-predlog
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(blanketprofit)
print(targetedprofit)
print(outperformance)
paste(round(100*outperformance, 2), "%")
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
bestpredictor<-predlog
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(blanketprofit)
print(targetedprofit)
print(outperformance)
paste(round(outperformance, 2), "%")
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
bestpredictor<-predlog
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(blanketprofit)
print(targetedprofit)
print(outperformance)
paste(round(outperformance, 2), "%", sep="")
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
bestpredictor<-predlog
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(blanketprofit)
print(targetedprofit)
paste(round(outperformance, 2), "%", sep="")
