print(caret::confusionMatrix(predlm.rose,bbtest$Choice)$table)
cat("\n")
###I don't understand these accuracy measures, do we need them?
print(accuracy.meas(bbtest$Choice,predlm))
print(accuracy.meas(bbtest$Choice,predlm.over))
print(accuracy.meas(bbtest$Choice,predlm.rose))
t.test(bbtrain$First_purchase[bbtrain$Choice==0],bbtrain$First_purchase[bbtrain$Choice==1])
table(bbtrain$First_purchase)
bbtrain$Choice<-as.factor(as.character(bbtrain$Choice))
plot(bbtrain$Choice,main="Unbalanced Dataset")
plot(bbtrain.over$Choice,main="Over-Sampling Dataset")
plot(bbtrain.rose$Choice,main="Synthetically Generated Dataset")
lmexample<-glm(Choice~Amount_purchased+P_Art,bbtrain,family=gaussian)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lmexample<-glm(Choice~Amount_purchased+P_Art,bbtrain,family=gaussian)
plot(Choice~Amount_purchased,data=bbtrain)
abline(example)
summary(example)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lmexample<-glm(Choice~Amount_purchased+P_Art,bbtrain,family=gaussian)
plot(Choice~Amount_purchased,data=bbtrain)
abline(lmexample)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lmexample<-glm(Choice~Amount_purchased,bbtrain,family=gaussian)
plot(Choice~Amount_purchased,data=bbtrain)
abline(lmexample)
bbtrain$Choice<-as.factor(bbtrain$Choice)
logexample<-glm(Choice~Amount_purchased+P_Art,bbtrain,family=binomial)
newdata<-data.frame(Amount_purchased=seq(min(bbtrain$Amount_purchased),max(bbtrain$Amount_purchased),len=500),P_Art=seq(min(bbtrain$P_Art),max(bbtrain$P_Art),len=500))
newdata$Choice<-predict(logexample,newdata,type='response')
plot(Choice~Amount_purchased,data=bbtrain)
lines(Choice~Amount_purchased,data=newdata)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lmexample<-glm(Choice~Amount_purchased,bbtrain,family=gaussian)
plot(Choice~Amount_purchased,data=bbtrain)
abline(lmexample)
#bbtrain$Choice<-as.factor(bbtrain$Choice)
logexample<-glm(Choice~Amount_purchased+P_Art,bbtrain,family=binomial)
newdata<-data.frame(Amount_purchased=seq(min(bbtrain$Amount_purchased),max(bbtrain$Amount_purchased),len=500),P_Art=seq(min(bbtrain$P_Art),max(bbtrain$P_Art),len=500))
newdata$Choice<-predict(logexample,newdata,type='response')
plot(Choice~Amount_purchased,data=bbtrain)
lines(Choice~Amount_purchased,data=newdata)
#cost is .65 per mail sent, book cost is 15 with overhead of 45% of cost, and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
predictions<-list(predlm,predlog,predlog_over,predlog_rose,predsvm,predsvm.over,predsvm.rose)
#cost is .65 per mail sent, book cost is 15 with overhead of 45% of cost, and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
predictions<-list(predlm,predlm.over,predlm.rosepredlog,predlog.over,predlog.rose,predsvm,predsvm.over,predsvm.rose)
#cost is .65 per mail sent, book cost is 15 with overhead of 45% of cost, and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
predictions<-list(predlm,predlm.over,predlm.rose,predlog,predlog.over,predlog.rose,predsvm,predsvm.over,predsvm.rose)
predlabel<-c("Raw Linear Regression","Balanced Linear Regression","Synthetic Linear Regression","Raw Logit","Balanced Logit","Synthetic Logit","Raw SVM","Balanced SVM","Synthetic SVM")
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
print("Profitability using Model to select mailers, vs mailing every Midwest customer")
print(paste("Profit mailing everyone: ","$",round(blanketprofit,2),sep=""))
for(i in 1:length(predictions)){
bestpredictor<-unlist(predictions[i])
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(predlabel[i])
print(paste(round(outperformance, 2), "%", sep=""))
}
buyerfraction
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(e1071)
library(ROSE)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies/Case2")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
# Check for Missing Values
sum(is.na(bbtrain))
sum(is.na(bbtest))
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
#balance the target classes
bbtrain.over<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
bbtrain.over$Choice <- factor(bbtrain.over$Class)
bbtrain.over$Class<-NULL
bbtrain.rose=ROSE(Choice~.,data=bbtrain,seed=12345)$data
# Train the unbalanced dataset for logistic regression model
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
#summary(log)
# Train the Over-sampled for logistic regression model
log_over<-glm(Choice~.-First_purchase,data=bbtrain.over,family=binomial)
#summary(log_over)
# Train the Synthetically generated  dataset for logistic regression model
log_rose<-glm(Choice~.-First_purchase,data=bbtrain.rose,family=binomial)
#summary(log_rose)
tunedsvm=tune("svm",Choice~.-First_purchase,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
#summary(svm)
tunedsvm_over=tune("svm",Choice~.-First_purchase,data=bbtrain.over,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm_over<-tunedsvm_over$best.model
#summary(svm_over)
tunedsvm_rose=tune("svm",Choice~.-First_purchase,data=bbtrain.rose,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm_rose<-tunedsvm_rose$best.model
#summary(svm_rose)
#convert factor back to numeric for linear regression
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
bbtrain.over$Choice<-as.numeric(as.character(bbtrain.over$Choice))
bbtrain.rose$Choice<-as.numeric(as.character(bbtrain.rose$Choice))
lm<-glm(Choice~.-First_purchase,data=bbtrain,family=gaussian)
lm_over<-glm(Choice~.-First_purchase,data=bbtrain.over,family=gaussian)
lm_rose<-glm(Choice~.-First_purchase,data=bbtrain.rose,family=gaussian)
#summary(lm)
#summary(lm_over)
#summary(lm_rose)
# Prediction using unbalanced Dataset
predlog<-predict(log,bbtest,type="response")
predsvm<-predict(svm,bbtest)
predlm<-predict(lm,bbtest)
predlog<-as.factor(ifelse(predlog>0.5,1,0))
predlm<-as.factor(ifelse(predlm>0.5,1,0))
# Prediction using Over sampled Dataset
predlog.over<-predict(log_over,bbtest,type="response")
predsvm.over<-predict(svm_over,bbtest)
predlm.over<-predict(lm_over,bbtest)
predlm.over<-as.factor(ifelse(predlm.over>0.5,1,0))
predlog.over<-as.factor(ifelse(predlog.over>0.5,1,0))
# Prediction using Synthetically Generated Dataset
predlog.rose<-predict(log_rose,bbtest,type="response")
predsvm.rose<-predict(svm_rose,bbtest)
predlm.rose<-predict(lm_rose,bbtest)
predlm.rose<-as.factor(ifelse(predlm.rose>0.5,1,0))
predlog.rose<-as.factor(ifelse(predlog.rose>0.5,1,0))
#Prediction and test are all ordered so 0 is the positive value, so reverse them here
bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
predlog<-factor(predlog,levels=rev(levels(predlog)))
predlog.over<-factor(predlog.over,levels=rev(levels(predlog.over)))
predlog.rose<-factor(predlog.rose,levels=rev(levels(predlog.rose)))
predsvm<-factor(predsvm,levels=rev(levels(predsvm)))
predsvm.over<-factor(predsvm.over,levels=rev(levels(predsvm.over)))
predsvm.rose<-factor(predsvm.rose,levels=rev(levels(predsvm.rose)))
predlm<-factor(predlm,levels=rev(levels(predlm)))
predlm.over<-factor(predlm.over,levels=rev(levels(predlm.over)))
predlm.rose<-factor(predlm.rose,levels=rev(levels(predlm.rose)))
print("Logit Unbalanced")
print(caret::confusionMatrix(predlog,bbtest$Choice)$table)
cat("\n")
print("Logit Overbalanced")
print(caret::confusionMatrix(predlog.over,bbtest$Choice)$table)
cat("\n")
print("Logit Synthetic balanced")
print(caret::confusionMatrix(predlog.rose,bbtest$Choice)$table)
cat("\n")
###I don't understand these accuracy measures, do we need them?
print(accuracy.meas(bbtest$Choice,predlog))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog.over))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog.rose))
cat("\n")
print("Logit ROC Curves")
roc.curve(bbtest$Choice,predlog,col="blue")
roc.curve(bbtest$Choice,predlog.over,add.roc = TRUE,col="green")
roc.curve(bbtest$Choice,predlog.rose,add.roc = TRUE,col="brown")
print("SVM Confusion Matrices")
print("SVM Unbalanced")
print(caret::confusionMatrix(predsvm,bbtest$Choice)$table)
cat("\n")
print("SVM Overbalanced")
print(caret::confusionMatrix(predsvm.over,bbtest$Choice)$table)
cat("\n")
print("SVM ROSE balanced")
print(caret::confusionMatrix(predsvm.rose,bbtest$Choice)$table)
cat("\n")
###I don't understand these accuracy measures, do we need them?
print(accuracy.meas(bbtest$Choice,predsvm))
cat("\n")
print(accuracy.meas(bbtest$Choice,predsvm.over))
cat("\n")
print(accuracy.meas(bbtest$Choice,predsvm.rose))
cat("\n")
print("SVM ROC Curves")
roc.curve(bbtest$Choice,predsvm,col="blue")
roc.curve(bbtest$Choice,predsvm.over,add.roc = TRUE,col="green")
roc.curve(bbtest$Choice,predsvm.rose,add.roc = TRUE,col="brown")
print("Linear Model Confusion Matrix")
print("Linear Unbalanced")
print(caret::confusionMatrix(predlm,bbtest$Choice)$table)
cat("\n")
print("Linear Overbalanced")
print(caret::confusionMatrix(predlm.over,bbtest$Choice)$table)
cat("\n")
print("Linear Synthetic balanced")
print(caret::confusionMatrix(predlm.rose,bbtest$Choice)$table)
cat("\n")
###I don't understand these accuracy measures, do we need them?
print(accuracy.meas(bbtest$Choice,predlm))
print(accuracy.meas(bbtest$Choice,predlm.over))
print(accuracy.meas(bbtest$Choice,predlm.rose))
t.test(bbtrain$First_purchase[bbtrain$Choice==0],bbtrain$First_purchase[bbtrain$Choice==1])
table(bbtrain$First_purchase)
bbtrain$Choice<-as.factor(as.character(bbtrain$Choice))
plot(bbtrain$Choice,main="Unbalanced Dataset")
plot(bbtrain.over$Choice,main="Over-Sampling Dataset")
plot(bbtrain.rose$Choice,main="Synthetically Generated Dataset")
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lmexample<-glm(Choice~Amount_purchased,bbtrain,family=gaussian)
plot(Choice~Amount_purchased,data=bbtrain)
abline(lmexample)
logexample<-glm(Choice~Amount_purchased+P_Art,bbtrain,family=binomial)
newdata<-data.frame(Amount_purchased=seq(min(bbtrain$Amount_purchased),max(bbtrain$Amount_purchased),len=500),P_Art=seq(min(bbtrain$P_Art),max(bbtrain$P_Art),len=500))
newdata$Choice<-predict(logexample,newdata,type='response')
plot(Choice~Amount_purchased,data=bbtrain)
lines(Choice~Amount_purchased,data=newdata)
#cost is .65 per mail sent, book cost is 15 with overhead of 45% of cost, and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
predictions<-list(predlm,predlm.over,predlm.rose,predlog,predlog.over,predlog.rose,predsvm,predsvm.over,predsvm.rose)
predlabel<-c("Raw Linear Regression","Balanced Linear Regression","Synthetic Linear Regression","Raw Logit","Balanced Logit","Synthetic Logit","Raw SVM","Balanced SVM","Synthetic SVM")
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
print("Profitability using Model to select mailers, vs mailing every Midwest customer")
print(paste("Profit mailing everyone: ","$",round(blanketprofit,2),sep=""))
for(i in 1:length(predictions)){
bestpredictor<-unlist(predictions[i])
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(predlabel[i])
print(paste(round(outperformance, 2), "%", sep=""))
}
buyerfraction
Midwestbase*buyerfraction)*profit)
Midwestbase*buyerfraction)*profit
Midwestbase*buyerfraction*profit
Midwestbase*mailcost
50000*0.65
summary(log_rose)
plot(as.numeric(as.character(bbtrain.rose$Choice)),main="Synthetically Generated Dataset")
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(e1071)
library(ROSE)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies/Case2")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
# Check for Missing Values
#sum(is.na(bbtrain))
#sum(is.na(bbtest))
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
#balance the target classes
bbtrain.over<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
bbtrain.over$Choice <- factor(bbtrain.over$Class)
bbtrain.over$Class<-NULL
bbtrain.rose=ROSE(Choice~.,data=bbtrain,seed=12345)$data
#Logistic Regression
# Train the unbalanced dataset for logistic regression model
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
#summary(log)
# Train the Over-sampled for logistic regression model
log_over<-glm(Choice~.-First_purchase,data=bbtrain.over,family=binomial)
#summary(log_over)
# Train the Synthetically generated  dataset for logistic regression model
log_rose<-glm(Choice~.-First_purchase,data=bbtrain.rose,family=binomial)
#summary(log_rose)
tunedsvm=tune("svm",Choice~.-First_purchase,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
#summary(svm)
tunedsvm_over=tune("svm",Choice~.-First_purchase,data=bbtrain.over,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(e1071)
library(ROSE)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies/Case2")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
# Check for Missing Values
#sum(is.na(bbtrain))
#sum(is.na(bbtest))
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
#balance the target classes
bbtrain.over<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
bbtrain.over$Choice <- factor(bbtrain.over$Class)
bbtrain.over$Class<-NULL
bbtrain.rose=ROSE(Choice~.,data=bbtrain,seed=12345)$data
#Logistic Regression
# Train the unbalanced dataset for logistic regression model
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
#summary(log)
# Train the Over-sampled for logistic regression model
log_over<-glm(Choice~.-First_purchase,data=bbtrain.over,family=binomial)
#summary(log_over)
# Train the Synthetically generated  dataset for logistic regression model
log_rose<-glm(Choice~.-First_purchase,data=bbtrain.rose,family=binomial)
#summary(log_rose)
tunedsvm=tune("svm",Choice~.-First_purchase,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(e1071)
library(ROSE)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies/Case2")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
# Check for Missing Values
#sum(is.na(bbtrain))
#sum(is.na(bbtest))
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
#balance the target classes
bbtrain.over<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
bbtrain.over$Choice <- factor(bbtrain.over$Class)
bbtrain.over$Class<-NULL
bbtrain.rose=ROSE(Choice~.,data=bbtrain,seed=12345)$data
#Logistic Regression
# Train the unbalanced dataset for logistic regression model
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
#summary(log)
# Train the Over-sampled for logistic regression model
log_over<-glm(Choice~.-First_purchase,data=bbtrain.over,family=binomial)
#summary(log_over)
# Train the Synthetically generated  dataset for logistic regression model
log_rose<-glm(Choice~.-First_purchase,data=bbtrain.rose,family=binomial)
#summary(log_rose)
tunedsvm=tune("svm",Choice~.-First_purchase,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
#summary(svm)
tunedsvm_over=tune("svm",Choice~.-First_purchase,data=bbtrain.over,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm_over<-tunedsvm_over$best.model
#summary(svm_over)
tunedsvm_rose=tune("svm",Choice~.-First_purchase,data=bbtrain.rose,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm_rose<-tunedsvm_rose$best.model
#summary(svm_rose)
# Linear Regression
#convert factor back to numeric for linear regression
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
bbtrain.over$Choice<-as.numeric(as.character(bbtrain.over$Choice))
bbtrain.rose$Choice<-as.numeric(as.character(bbtrain.rose$Choice))
lm<-glm(Choice~.-First_purchase,data=bbtrain,family=gaussian)
lm_over<-glm(Choice~.-First_purchase,data=bbtrain.over,family=gaussian)
lm_rose<-glm(Choice~.-First_purchase,data=bbtrain.rose,family=gaussian)
#summary(lm)
#summary(lm_over)
#summary(lm_rose)
# Prediction using unbalanced Dataset
predlog<-predict(log,bbtest,type="response")
predsvm<-predict(svm,bbtest)
predlm<-predict(lm,bbtest)
predlog<-as.factor(ifelse(predlog>0.5,1,0))
predlm<-as.factor(ifelse(predlm>0.5,1,0))
# Prediction using Over sampled Dataset
predlog.over<-predict(log_over,bbtest,type="response")
predsvm.over<-predict(svm_over,bbtest)
predlm.over<-predict(lm_over,bbtest)
predlm.over<-as.factor(ifelse(predlm.over>0.5,1,0))
predlog.over<-as.factor(ifelse(predlog.over>0.5,1,0))
# Prediction using Synthetically Generated Dataset
predlog.rose<-predict(log_rose,bbtest,type="response")
predsvm.rose<-predict(svm_rose,bbtest)
predlm.rose<-predict(lm_rose,bbtest)
predlm.rose<-as.factor(ifelse(predlm.rose>0.5,1,0))
predlog.rose<-as.factor(ifelse(predlog.rose>0.5,1,0))
#Prediction and test are all ordered so 0 is the positive value, so reverse them here
bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
predlog<-factor(predlog,levels=rev(levels(predlog)))
predlog.over<-factor(predlog.over,levels=rev(levels(predlog.over)))
predlog.rose<-factor(predlog.rose,levels=rev(levels(predlog.rose)))
predsvm<-factor(predsvm,levels=rev(levels(predsvm)))
predsvm.over<-factor(predsvm.over,levels=rev(levels(predsvm.over)))
predsvm.rose<-factor(predsvm.rose,levels=rev(levels(predsvm.rose)))
predlm<-factor(predlm,levels=rev(levels(predlm)))
predlm.over<-factor(predlm.over,levels=rev(levels(predlm.over)))
predlm.rose<-factor(predlm.rose,levels=rev(levels(predlm.rose)))
t.test(bbtrain$First_purchase[bbtrain$Choice==0],bbtrain$First_purchase[bbtrain$Choice==1])
table(bbtrain$First_purchase)
bbtrain$Choice<-as.factor(as.character(bbtrain$Choice))
plot(bbtrain$Choice,main="Unbalanced Dataset")
bbtrain.over$Choice<-as.factor(as.character(bbtrain.over$Choice))
plot(bbtrain.over$Choice,main="Over-Sampling Dataset")
bbtrain.rose$Choice<-as.factor(as.character(bbtrain.rose$Choice))
plot(bbtrain.rose$Choice,main="Synthetically Generated Dataset")
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lmexample<-glm(Choice~Amount_purchased,bbtrain,family=gaussian)
plot(Choice~Amount_purchased,data=bbtrain)
abline(lmexample)
logexample<-glm(Choice~Amount_purchased+P_Art,bbtrain,family=binomial)
newdata<-data.frame(Amount_purchased=seq(min(bbtrain$Amount_purchased),max(bbtrain$Amount_purchased),len=500),P_Art=seq(min(bbtrain$P_Art),max(bbtrain$P_Art),len=500))
newdata$Choice<-predict(logexample,newdata,type='response')
plot(Choice~Amount_purchased,data=bbtrain)
lines(Choice~Amount_purchased,data=newdata)
print("Logit Unbalanced")
print(caret::confusionMatrix(predlog,bbtest$Choice)$table)
cat("\n")
print("Logit Overbalanced")
print(caret::confusionMatrix(predlog.over,bbtest$Choice)$table)
cat("\n")
print("Logit Synthetic balanced")
print(caret::confusionMatrix(predlog.rose,bbtest$Choice)$table)
cat("\n")
###I don't understand these accuracy measures, do we need them?
print(accuracy.meas(bbtest$Choice,predlog))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog.over))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog.rose))
cat("\n")
print("Logit ROC Curves")
roc.curve(bbtest$Choice,predlog,col="blue")
roc.curve(bbtest$Choice,predlog.over,add.roc = TRUE,col="green")
roc.curve(bbtest$Choice,predlog.rose,add.roc = TRUE,col="brown")
print("SVM Confusion Matrices")
print("SVM Unbalanced")
print(caret::confusionMatrix(predsvm,bbtest$Choice)$table)
cat("\n")
print("SVM Overbalanced")
print(caret::confusionMatrix(predsvm.over,bbtest$Choice)$table)
cat("\n")
print("SVM ROSE balanced")
print(caret::confusionMatrix(predsvm.rose,bbtest$Choice)$table)
cat("\n")
###I don't understand these accuracy measures, do we need them?
print(accuracy.meas(bbtest$Choice,predsvm))
cat("\n")
print(accuracy.meas(bbtest$Choice,predsvm.over))
cat("\n")
print(accuracy.meas(bbtest$Choice,predsvm.rose))
cat("\n")
print("SVM ROC Curves")
roc.curve(bbtest$Choice,predsvm,col="blue")
roc.curve(bbtest$Choice,predsvm.over,add.roc = TRUE,col="green")
roc.curve(bbtest$Choice,predsvm.rose,add.roc = TRUE,col="brown")
print("Linear Model Confusion Matrix")
print("Linear Unbalanced")
print(caret::confusionMatrix(predlm,bbtest$Choice)$table)
cat("\n")
print("Linear Overbalanced")
print(caret::confusionMatrix(predlm.over,bbtest$Choice)$table)
cat("\n")
print("Linear Synthetic balanced")
print(caret::confusionMatrix(predlm.rose,bbtest$Choice)$table)
cat("\n")
###I don't understand these accuracy measures, do we need them?
print(accuracy.meas(bbtest$Choice,predlm))
print(accuracy.meas(bbtest$Choice,predlm.over))
print(accuracy.meas(bbtest$Choice,predlm.rose))
#cost is .65 per mail sent, book cost is 15 with overhead of 45% of cost, and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
predictions<-list(predlm,predlm.over,predlm.rose,predlog,predlog.over,predlog.rose,predsvm,predsvm.over,predsvm.rose)
predlabel<-c("Raw Linear Regression","Balanced Linear Regression","Synthetic Linear Regression","Raw Logit","Balanced Logit","Synthetic Logit","Raw SVM","Balanced SVM","Synthetic SVM")
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
print("Profitability using Model to select mailers, vs mailing every Midwest customer")
print(paste("Profit mailing everyone: ","$",round(blanketprofit,2),sep=""))
for(i in 1:length(predictions)){
bestpredictor<-unlist(predictions[i])
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(predlabel[i])
print(paste(round(outperformance, 2), "%", sep=""))
}
summary(log_rose)
