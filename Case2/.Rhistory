#str(bbtrain)
#str(bbtest)
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
#view the distribution of target variable
plot(bbtrain$Choice)
#balance the target classes
bbtrain.over<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
bbtrain.over$Choice <- factor(bbtrain.over$Class)
bbtrain.over$Class<-NULL
bbtrain.rose=ROSE(Choice~.,data=bbtrain,seed=12345)$data
plot(bbtrain.over$Choice)
plot(bbtrain.rose$Choice)
#boruta_var_imp_output=Boruta(Choice~.,data=bbtrain,doTrace=1)
#boruta_signif <- getSelectedAttributes(boruta_var_imp_output, withTentative = TRUE)
#boruta_roug_fix_mod=TentativeRoughFix(boruta_var_imp_output)
# Variable Importance Scores#
#boruta_imps <- attStats(boruta_roug_fix_mod)
#boruta_imps2 = boruta_imps[boruta_imps$decision != 'Rejected', c('meanImp', 'decision')]
#boruta_imps2[order(-boruta_imps2$meanImp), ]
#plot(boruta_var_imp_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
# Train the unbalanced dataset for logistic regression model
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
summary(log)
# Train the Over-sampled for logistic regression model
log_over<-glm(Choice~.-First_purchase,data=bbtrain.over,family=binomial)
summary(log_over)
# Train the Synthetically generated  dataset for logistic regression model
log_rose<-glm(Choice~.-First_purchase,data=bbtrain.rose,family=binomial)
summary(log_rose)
tunedsvm=tune("svm",Choice~.,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
summary(svm)
tunedsvm_over=tune("svm",Choice~.,data=bbtrain.over,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm_over<-tunedsvm_over$best.model
summary(svm_over)
tunedsvm_rose=tune("svm",Choice~.,data=bbtrain.rose,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm_rose<-tunedsvm_rose$best.model
summary(svm_rose)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lm<-glm(Choice~.,data=bbtrain,family=gaussian)
summary(lm)
predsvm<-predict(svm,bbtest)
predsvm.over<-predict(svm_over,bbtest)
predsvm.rose<-predict(svm_over,bbtest)
predlm<-predict(lm,bbtest)
predlm<-as.factor(ifelse(predlm>0.5,1,0))
# Prediction using Logistic Regression with unbalanced Dataset
predlog<-predict(log,bbtest,type="response")
predlog<-as.factor(ifelse(predlog>0.5,0,1))
predlog<-as.factor(ifelse(predlog>0.5,1,0))
# Prediction using Logistic Regression with unbalanced Dataset
predlog<-predict(log,bbtest,type="response")
predlog<-as.factor(ifelse(predlog>0.5,1,0))
# Prediction using Logistic Regression with unbalanced Dataset
predlog<-predict(log,bbtest,type="response")
predlog<-as.factor(ifelse(predlog>0.5,1,0))
# Prediction using Logistic Regression with Over sampled Dataset
predlog_over<-predict(log_over,bbtest,type="response")
predlog_over<-as.factor(ifelse(predlog_over>0.5,1,0))
# Prediction using Logistic Regression with Synthetically Generated Dataset
predlog_rose<-predict(log_rose,bbtest,type="response")
predlog_rose<-as.factor(ifelse(predlog_rose>0.5,1,0))
bbtest$Choice
bbtest$Choice<-as.factor(bbtest$Choice)
bbtest$Choice
bbtest$Choice<-as.factor(bbtest$Choice)
#bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
print(caret::confusionMatrix(predlog,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlog_over,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlog_rose,bbtest$Choice))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog_over))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog_rose))
cat("\n")
bbtest$Choice<-as.factor(bbtest$Choice)
#Prediction and test are all ordered so 0 is the positive value, so reverse them here
bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
predlog<-factor(predlog,levels=rev(levels(predlog)))
predlog_over<-factor(predlog_over,levels=rev(levels(predlog_over)))
predlog_rose<-factor(predlog_rose,levels=rev(levels(predlog_rose)))
predsvm<-factor(predsvm,levels=rev(levels(predsvm)))
predsvm.over<-factor(predsvm.over,levels=rev(levels(predsvm.over)))
predsvm.rose<-factor(predsvm.rose,levels=rev(levels(predsvm.rose)))
predlm<-factor(predlm,levels=rev(levels(predlm)))
print(caret::confusionMatrix(predlog,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlog_over,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlog_rose,bbtest$Choice))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog_over))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog_rose))
cat("\n")
roc.curve(bbtest$Choice,predlog,col="blue")
roc.curve(bbtest$Choice,predlog_over,add.roc = TRUE,col="green")
roc.curve(bbtest$Choice,predlog_rose,add.roc = TRUE,col="brown")
print(caret::confusionMatrix(as.factor(predsvm),bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm.over,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm.rose,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm.over,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm.rose,bbtest$Choice))
cat("\n")
roc.curve(bbtest$Choice,predsvm,col="blue")
roc.curve(bbtest$Choice,predsvm.over,add.roc = TRUE,col="green")
roc.curve(bbtest$Choice,predsvm.rose,add.roc = TRUE,col="brown")
print(caret::confusionMatrix(predlm,bbtest$Choice))
cat("\n")
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
#bestpredictor<-factor(predsvm,levels=rev(levels(predsvm)))
bestpredictor<-predlog
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(blanketprofit)
print(targetedprofit)
paste(round(outperformance, 2), "%", sep="")
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
#bestpredictor<-factor(predsvm,levels=rev(levels(predsvm)))
bestpredictor<-predsvm
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(blanketprofit)
print(targetedprofit)
paste(round(outperformance, 2), "%", sep="")
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
#bestpredictor<-factor(predsvm,levels=rev(levels(predsvm)))
bestpredictor<-predlog_over
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(blanketprofit)
print(targetedprofit)
paste(round(outperformance, 2), "%", sep="")
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
#bestpredictor<-factor(predsvm,levels=rev(levels(predsvm)))
bestpredictor<-predsvm.over
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(blanketprofit)
print(targetedprofit)
paste(round(outperformance, 2), "%", sep="")
plot(bbtrain$Choice,main="Unbalanced Dataset")
str(bbtrain$Choice)
str(bbtrain.over$Choice)
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(InformationValue)
library(e1071)
library(ROSE)
library(pROC)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies/Case2")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
#str(bbtrain)
#str(bbtest)
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
#view the distribution of target variable
plot(bbtrain$Choice)
#balance the target classes
bbtrain.over<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
bbtrain.over$Choice <- factor(bbtrain.over$Class)
bbtrain.over$Class<-NULL
bbtrain.rose=ROSE(Choice~.,data=bbtrain,seed=12345)$data
plot(bbtrain.over$Choice)
plot(bbtrain.rose$Choice)
#boruta_var_imp_output=Boruta(Choice~.,data=bbtrain,doTrace=1)
#boruta_signif <- getSelectedAttributes(boruta_var_imp_output, withTentative = TRUE)
#boruta_roug_fix_mod=TentativeRoughFix(boruta_var_imp_output)
# Variable Importance Scores#
#boruta_imps <- attStats(boruta_roug_fix_mod)
#boruta_imps2 = boruta_imps[boruta_imps$decision != 'Rejected', c('meanImp', 'decision')]
#boruta_imps2[order(-boruta_imps2$meanImp), ]
#plot(boruta_var_imp_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
# Train the unbalanced dataset for logistic regression model
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
summary(log)
# Train the Over-sampled for logistic regression model
log_over<-glm(Choice~.-First_purchase,data=bbtrain.over,family=binomial)
summary(log_over)
# Train the Synthetically generated  dataset for logistic regression model
log_rose<-glm(Choice~.-First_purchase,data=bbtrain.rose,family=binomial)
summary(log_rose)
tunedsvm=tune("svm",Choice~.,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
summary(svm)
tunedsvm_over=tune("svm",Choice~.,data=bbtrain.over,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm_over<-tunedsvm_over$best.model
summary(svm_over)
tunedsvm_rose=tune("svm",Choice~.,data=bbtrain.rose,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm_rose<-tunedsvm_rose$best.model
summary(svm_rose)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lm<-glm(Choice~.,data=bbtrain,family=gaussian)
summary(lm)
predsvm<-predict(svm,bbtest)
predsvm.over<-predict(svm_over,bbtest)
predsvm.rose<-predict(svm_over,bbtest)
predlm<-predict(lm,bbtest)
predlm<-as.factor(ifelse(predlm>0.5,1,0))
# Prediction using Logistic Regression with unbalanced Dataset
predlog<-predict(log,bbtest,type="response")
predlog<-as.factor(ifelse(predlog>0.5,1,0))
# Prediction using Logistic Regression with Over sampled Dataset
predlog_over<-predict(log_over,bbtest,type="response")
predlog_over<-as.factor(ifelse(predlog_over>0.5,1,0))
# Prediction using Logistic Regression with Synthetically Generated Dataset
predlog_rose<-predict(log_rose,bbtest,type="response")
predlog_rose<-as.factor(ifelse(predlog_rose>0.5,1,0))
bbtest$Choice<-as.factor(bbtest$Choice)
#Prediction and test are all ordered so 0 is the positive value, so reverse them here
bbtest$Choice<-factor(bbtest$Choice,levels=rev(levels(bbtest$Choice)))
predlog<-factor(predlog,levels=rev(levels(predlog)))
predlog_over<-factor(predlog_over,levels=rev(levels(predlog_over)))
predlog_rose<-factor(predlog_rose,levels=rev(levels(predlog_rose)))
predsvm<-factor(predsvm,levels=rev(levels(predsvm)))
predsvm.over<-factor(predsvm.over,levels=rev(levels(predsvm.over)))
predsvm.rose<-factor(predsvm.rose,levels=rev(levels(predsvm.rose)))
predlm<-factor(predlm,levels=rev(levels(predlm)))
print(caret::confusionMatrix(predlog,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlog_over,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predlog_rose,bbtest$Choice))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog_over))
cat("\n")
print(accuracy.meas(bbtest$Choice,predlog_rose))
cat("\n")
roc.curve(bbtest$Choice,predlog,col="blue")
roc.curve(bbtest$Choice,predlog_over,add.roc = TRUE,col="green")
roc.curve(bbtest$Choice,predlog_rose,add.roc = TRUE,col="brown")
print(caret::confusionMatrix(predsvm,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm.over,bbtest$Choice))
cat("\n")
print(caret::confusionMatrix(predsvm.rose,bbtest$Choice))
cat("\n")
roc.curve(bbtest$Choice,predsvm,col="blue")
roc.curve(bbtest$Choice,predsvm.over,add.roc = TRUE,col="green")
roc.curve(bbtest$Choice,predsvm.rose,add.roc = TRUE,col="brown")
print(caret::confusionMatrix(predlm,bbtest$Choice))
cat("\n")
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
#bestpredictor<-factor(predsvm,levels=rev(levels(predsvm)))
bestpredictor<-predsvm.over
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(blanketprofit)
print(targetedprofit)
paste(round(outperformance, 2), "%", sep="")
plot(bbtrain$Choice,main="Unbalanced Dataset")
plot(bbtrain.over$Choice,main="Over-Sampling Dataset")
predictions<-list(predlm,predlog,predlog_over,predlog_rose,predsvm,predsvm.over,predsvm.rose)
length(predictions)
range(1:7)
1:7
1:length(predictions)
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
predictions<-list(predlm,predlog,predlog_over,predlog_rose,predsvm,predsvm.over,predsvm.rose)
predlabel<-c("Balanced Linear Regression","Raw Logit","Balanced Logit","Synthetic Logit","Raw SVM","Balanced SVM","Synthetic SVM")
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
for(i in 1:length(predictions)){
bestpredictor<-unlist(predictions[i])
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(predlabel[i])
paste(round(outperformance, 2), "%", sep="")
}
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
predictions<-list(predlm,predlog,predlog_over,predlog_rose,predsvm,predsvm.over,predsvm.rose)
predlabel<-c("Balanced Linear Regression","Raw Logit","Balanced Logit","Synthetic Logit","Raw SVM","Balanced SVM","Synthetic SVM")
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
for(i in 1:length(predictions)){
bestpredictor<-unlist(predictions[i])
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(predlabel[i])
print(paste(round(outperformance, 2), "%", sep=""))
}
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
print("Profitability using Model to select mailers, vs mailing every Midwest customer")
predictions<-list(predlm,predlog,predlog_over,predlog_rose,predsvm,predsvm.over,predsvm.rose)
predlabel<-c("Balanced Linear Regression","Raw Logit","Balanced Logit","Synthetic Logit","Raw SVM","Balanced SVM","Synthetic SVM")
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
for(i in 1:length(predictions)){
bestpredictor<-unlist(predictions[i])
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(predlabel[i])
print(paste(round(outperformance, 2), "%", sep=""))
}
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
predictions<-list(predlm,predlog,predlog_over,predlog_rose,predsvm,predsvm.over,predsvm.rose)
predlabel<-c("Balanced Linear Regression","Raw Logit","Balanced Logit","Synthetic Logit","Raw SVM","Balanced SVM","Synthetic SVM")
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
print("Profitability using Model to select mailers, vs mailing every Midwest customer")
print(paste("Profit mailing everyone: ","$",blanketprofit,sep=""))
for(i in 1:length(predictions)){
bestpredictor<-unlist(predictions[i])
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(predlabel[i])
print(paste(round(outperformance, 2), "%", sep=""))
}
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
predictions<-list(predlm,predlog,predlog_over,predlog_rose,predsvm,predsvm.over,predsvm.rose)
predlabel<-c("Balanced Linear Regression","Raw Logit","Balanced Logit","Synthetic Logit","Raw SVM","Balanced SVM","Synthetic SVM")
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
print("Profitability using Model to select mailers, vs mailing every Midwest customer")
print(paste("Profit mailing everyone: ","$",round(blanketprofit,2),sep=""))
for(i in 1:length(predictions)){
bestpredictor<-unlist(predictions[i])
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(predlabel[i])
print(paste(round(outperformance, 2), "%", sep=""))
}
#cost is .65 per mail sent, book cost with overhead costs 15*1.45 and selling price is 31.95
#The following assumes that Midwest will have a similar buying population as the test data
predictions<-list(predlm,predlog,predlog_over,predlog_rose,predsvm,predsvm.over,predsvm.rose)
predlabel<-c("Balanced Linear Regression","Raw Logit","Balanced Logit","Synthetic Logit","Raw SVM","Balanced SVM","Synthetic SVM")
mailcost<-0.65
profit<-31.95-(15*1.45)
Midwestbase<-50000
buyerfraction<-sum(bbtest$Choice==1)/length(bbtest$Choice)
blanketprofit<-((Midwestbase*buyerfraction)*profit)-(Midwestbase*mailcost)
print("Profitability using Model to select mailers, vs mailing every Midwest customer")
print(paste("Profit mailing everyone: ","$",round(blanketprofit,2),sep=""))
for(i in 1:length(predictions)){
bestpredictor<-unlist(predictions[i])
#percentage of buy predictions made by model and percentage of buy predictions that are correct
detectionprevalence<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[10])
pospredvalue<-as.numeric(caret::confusionMatrix(bestpredictor,bbtest$Choice)$byClass[3])
targetedprofit<-((Midwestbase*detectionprevalence*pospredvalue)*profit)-(Midwestbase*detectionprevalence*mailcost)
outperformance<-(targetedprofit-blanketprofit)*100/blanketprofit
print(predlabel[i])
print(paste(round(outperformance, 2), "%", sep=""))
}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(caret)
library(Boruta)
library(Rcpp)
library(InformationValue)
library(e1071)
library(ROSE)
library(pROC)
setwd("~/GitHub/DA6813CaseStudies/Case2")
#setwd("~/MSDA/Fall 2021/GitHub")
#setwd("~/MSDA/Fall 2021/GitHub/DA6813CaseStudies")
#setwd("~/MSDA/Fall 2021/Data Analytics Applications/Case Study 1/DA6813CaseStudies/Case2")
set.seed(12345)
bbtrain<-read_excel('BBBC-Train.xlsx')
bbtest<-read_excel('BBBC-Test.xlsx')
bbtrain$Choice<-as.factor(bbtrain$Choice)
bbtest$Choice<-as.factor(bbtest$Choice)
#str(bbtrain)
#str(bbtest)
#remove the index column
bbtrain<-bbtrain[-1]
bbtest<-bbtest[-1]
#view the distribution of target variable
plot(bbtrain$Choice)
#balance the target classes
bbtrain.over<-upSample(x=bbtrain[,2:ncol(bbtrain)],y=bbtrain$Choice)
bbtrain.over$Choice <- factor(bbtrain.over$Class)
bbtrain.over$Class<-NULL
bbtrain.rose=ROSE(Choice~.,data=bbtrain,seed=12345)$data
plot(bbtrain.over$Choice)
plot(bbtrain.rose$Choice)
#boruta_var_imp_output=Boruta(Choice~.,data=bbtrain,doTrace=1)
#boruta_signif <- getSelectedAttributes(boruta_var_imp_output, withTentative = TRUE)
#boruta_roug_fix_mod=TentativeRoughFix(boruta_var_imp_output)
# Variable Importance Scores#
#boruta_imps <- attStats(boruta_roug_fix_mod)
#boruta_imps2 = boruta_imps[boruta_imps$decision != 'Rejected', c('meanImp', 'decision')]
#boruta_imps2[order(-boruta_imps2$meanImp), ]
#plot(boruta_var_imp_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
# Train the unbalanced dataset for logistic regression model
log<-glm(Choice~.-First_purchase,data=bbtrain,family=binomial)
summary(log)
# Train the Over-sampled for logistic regression model
log_over<-glm(Choice~.-First_purchase,data=bbtrain.over,family=binomial)
summary(log_over)
# Train the Synthetically generated  dataset for logistic regression model
log_rose<-glm(Choice~.-First_purchase,data=bbtrain.rose,family=binomial)
summary(log_rose)
tunedsvm=tune("svm",Choice~.,data=bbtrain,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm<-tunedsvm$best.model
summary(svm)
tunedsvm_over=tune("svm",Choice~.,data=bbtrain.over,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm_over<-tunedsvm_over$best.model
summary(svm_over)
tunedsvm_rose=tune("svm",Choice~.,data=bbtrain.rose,kernel ="linear",ranges=list(cost=c( 0.001, 0.01, 1,5)))
svm_rose<-tunedsvm_rose$best.model
summary(svm_rose)
bbtrain$Choice<-as.numeric(as.character(bbtrain$Choice))
lm<-glm(Choice~.,data=bbtrain.over,family=gaussian)
bbtrain$Choice<-as.factor(as.character(bbtrain$Choice))
plot(bbtrain$Choice,main="Unbalanced Dataset")
