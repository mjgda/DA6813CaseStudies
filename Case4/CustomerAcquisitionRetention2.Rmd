---
title: "CustomerAcquisitionRetention"
author: "Visha Arumugam, Michael Grogan,Sanyogita Apte"
date: "11/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(SMCRM) # CRM data
library(dplyr) # data wrangling
library(tidyr) # data wrangling
library(ggplot2) # plotting
library(rpart) # DT
library(randomForestSRC) # RF
library(sampleSelection)



data(acquisitionRetention)
AR<-acquisitionRetention

idx.train <- sample(1:nrow(AR), size = 0.7 * nrow(AR))
train <- AR[idx.train,]
test <- AR[-idx.train,]

set.seed(123)

```



Formulas
```{r}
acq_vars<-c("acq_exp","acq_exp_sq","industry","revenue","employees")
acq_target<-"acquisition"

acq_formula<-as.formula(paste(acq_target,paste(acq_vars,collapse="+"),sep="~"))


dur_vars<-c("ret_exp","ret_exp_sq","freq","freq_sq","crossbuy","sow","IMR")

dur_target<-"duration"

dur_formula<-as.formula(paste(dur_target,paste(dur_vars,collapse="+"),sep="~"))

```





Logistic Regression
```{r}
###Logistic Acquisition prediction
acq_lm<-glm(acq_formula,train,family=binomial(link="probit"))



acq_lm_train_pred<-ifelse(predict(acq_lm,train,type="response")>0.5,1,0)

#Confusion Matrix
#table(acq_lm_train_pred,train$acquisition)
acq_lm_train_acc<-sum(acq_lm_train_pred==train$acquisition)/length(train$acquisition)



acq_lm_test_pred<-ifelse(predict(acq_lm,test,type="response")>0.5,1,0)

#Confusion Matrix
#table(acq_lm_test_pred,test$acquisition)
acq_lm_test_acc<-sum(acq_lm_test_pred==test$acquisition)/length(test$acquisition)
```

```{r}
####Logistic Duration Prediction
train$IMR<-invMillsRatio(glm(acq_formula,train,family=binomial(link="probit")))$IMR1

dur_lm<-glm(dur_formula,train,family=gaussian)

dur_lm_train_RMSE<-sqrt(mean(dur_lm$residuals^2))


test$IMR<-invMillsRatio(glm(acq_formula,test,family=binomial(link="probit")))$IMR1

dur_pred<-predict(dur_lm,test)
dur_lm_test_RMSE<-sqrt(mean((dur_pred-test$duration)^2))
```

Single Decision Tree

```{r}
acq_dt<-rpart(acq_formula,train)
dur_dt<-rpart(dur_formula,train)
```


```{r}
acq_dt_train_pred<-ifelse(predict(acq_dt,train)>0.5,1,0)
acq_dt_train_acc<-sum(acq_dt_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_dt_train_pred,train$acquisition)


acq_dt_test_pred<-ifelse(predict(acq_dt,test)>0.5,1,0)
acq_dt_test_acc<-sum(acq_dt_test_pred==test$acquisition)/length(test$acquisition)
#Confusion Matrix
#table(acq_dt_test_pred,test$acquisition)


dur_dt_train_pred<-predict(dur_dt,train)
dur_dt_train_RMSE<-sqrt(mean((dur_dt_train_pred-train$duration)^2))


dur_dt_test_pred<-predict(dur_dt,test)
dur_dt_test_RMSE<-sqrt(mean((dur_dt_test_pred-test$duration)^2))
```



Un-tuned Random Forest
```{r}
untuned_acq <- rfsrc(acq_formula,data = train,importance = TRUE)
```


```{r}
acq_untunedrf_train_pred<-ifelse(predict(untuned_acq,train)$predicted>0.5,1,0)
acq_untunedrf_train_acc<-sum(acq_untunedrf_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_untunedrf_train_pred,train$acquisition)


acq_untunedrf_test_pred<-ifelse(predict(untuned_acq,test)$predicted>0.5,1,0)
acq_untunedrf_test_acc<-sum(acq_untunedrf_test_pred==test$acquisition)/length(test$acquisition)

#Confusion Matrix
#table(acq_untunedrf_test_pred,test$acquisition)
```


```{r}
untuned_dur <- rfsrc(dur_formula,data = train,importance = TRUE)
```


```{r}
dur_untunedrf_train_pred<-predict(untuned_dur,train)$predicted
dur_untunedrf_train_RMSE<-sqrt(mean((dur_untunedrf_train_pred-train$duration)^2))
     

dur_untunedrf_test_pred<-predict(untuned_dur,test)$predicted
dur_untunedrf_test_RMSE<-sqrt(mean((dur_untunedrf_test_pred-test$duration)^2))


```





Tuned Random Forest

```{r}
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(3,8,1)
nodesize.values <- seq(4,12,2)
ntree.values <- seq(3e3,9e3,1e3)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)

# Create an empty vector to store OOB error values
oob_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {

    # Train a Random Forest model
   model <- rfsrc(acq_formula,data = train,
                            mtry = hyper_grid$mtry[i],
                            nodesize = hyper_grid$nodesize[i],
                            ntree = hyper_grid$ntree[i])  
  
                          
    # Store OOB error for the model                      
    oob_err[i] <- model$err.rate[length(model$err.rate)]
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)



tuned_acq <- rfsrc(acq_formula,data = train,
                            mtry = hyper_grid[opt_i,1],
                            nodesize = hyper_grid[opt_i,2],
                            ntree = hyper_grid[opt_i,3])
```


```{r}
acq_tunedrf_train_pred<-ifelse(predict(tuned_acq,train)$predicted>0.5,1,0)
acq_tunedrf_train_acc<-sum(acq_tunedrf_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_tunedrf_train_pred,train$acquisition)


acq_tunedrf_test_pred<-ifelse(predict(tuned_acq,test)$predicted>0.5,1,0)
acq_tunedrf_test_acc<-sum(acq_tunedrf_test_pred==test$acquisition)/length(test$acquisition)

#Confusion Matrix
#table(acq_tunedrf_test_pred,test$acquisition)

```




```{r}
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(3,8,1)
nodesize.values <- seq(4,12,2)
ntree.values <- seq(3e3,9e3,1e3)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)

# Create an empty vector to store OOB error values
oob_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {

    # Train a Random Forest model
   model <- rfsrc(dur_formula,data = train,
                            mtry = hyper_grid$mtry[i],
                            nodesize = hyper_grid$nodesize[i],
                            ntree = hyper_grid$ntree[i])  
  
                          
    # Store OOB error for the model                      
    oob_err[i] <- model$err.rate[length(model$err.rate)]
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)



tuned_dur <- rfsrc(dur_formula,data = train,
                            mtry = hyper_grid[opt_i,1],
                            nodesize = hyper_grid[opt_i,2],
                            ntree = hyper_grid[opt_i,3])
```


```{r}
dur_tunedrf_train_pred<-predict(tuned_dur,train)$predicted
dur_tunedrf_train_RMSE<-sqrt(mean((dur_tunedrf_train_pred-train$duration)^2))
     

dur_tunedrf_test_pred<-predict(tuned_dur,test)$predicted
dur_tunedrf_test_RMSE<-sqrt(mean((dur_tunedrf_test_pred-test$duration)^2))

```



Results

```{r}

testaccuracies<-c(acq_tunedrf_test_acc,acq_untunedrf_test_acc,acq_lm_test_acc,acq_dt_test_acc)
trainaccuracies<-c(acq_tunedrf_train_acc,acq_untunedrf_train_acc,acq_lm_train_acc,acq_dt_train_acc)
testRMSE<-c(dur_tunedrf_test_RMSE,dur_untunedrf_test_RMSE,dur_lm_test_RMSE,dur_dt_test_RMSE)
trainRMSE<-c(dur_tunedrf_train_RMSE,dur_untunedrf_train_RMSE,dur_lm_train_RMSE,dur_dt_train_RMSE)

model<-c("Tuned Random Forest","Untuned Random Forest","Linear Model","Decision Tree")

results<-data.frame(model,trainaccuracies,trainRMSE,testaccuracies,testRMSE)

results

```


```{r}
for(i in acq_vars){
sequence_<-seq(quantile(AR[[i]])[[2]],quantile(AR[[i]])[[4]],(quantile(AR[[i]])[[2]]-quantile(AR[[i]])[[4]])/-30)
means.exp<-partial(untuned_acq,partial.xvar = i,
                           partial.values = sequence_)$regrOutput$acquisition %>% colMeans()

marginal.effect.df <-
  data.frame(pred.acquisition = means.exp, sequence_ = sequence_)

print(
  ggplot(marginal.effect.df, aes(x = sequence_, y = pred.acquisition)) +
  geom_point(shape = 20, color = "purple", size = 2, stroke = 1.5)+
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), se = FALSE, color = "black")+
  labs(x = i, y = "Predicted acquisition") 
  
  )
}




for(i in dur_vars[-7]){
sequence_<-seq(quantile(AR[[i]])[[2]],quantile(AR[[i]])[[4]],(quantile(AR[[i]])[[2]]-quantile(AR[[i]])[[4]])/-30)
means.exp<-partial(untuned_dur,partial.xvar = i,
                           partial.values = sequence_)$regrOutput$duration %>% colMeans()

marginal.effect.df <-
  data.frame(pred.duration = means.exp, sequence_ = sequence_)

print(
  ggplot(marginal.effect.df, aes(x = sequence_, y = pred.duration)) +
  geom_point(shape = 20, color = "purple", size = 2, stroke = 1.5)+
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), se = FALSE, color = "black")+
  labs(x = i, y = "Predicted duration") 
  
  )
}


data.frame(importance = untuned_acq$importance) %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "violet", color = "black")+
    coord_flip() +
     labs(x = "Variables", y = "Variable importance")

data.frame(importance = untuned_dur$importance) %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "violet", color = "black")+
    coord_flip() +
     labs(x = "Variables", y = "Variable importance")


rattle::fancyRpartPlot(dur_dt, sub = "")
rattle::fancyRpartPlot(acq_dt, sub = "")

```
```{r}

find.interaction(untuned_dur,
                      method = "vimp",
                      importance = "permute")
```


## I - Executive Summary


## II - The Problem
Firms need to optimally allocate their resources in pursuing new clients as well as keeping their profitable current clients for as long as they can. The balancing act can be made easier by making predictions for which clients are likely to be acquired/retained given their associated data and spending money on those clients.

## III - Review of Related Literature


  
## IV - Methodology



## V - Data
The values available to a firm trying to determine which clients they are likely to acquire would not include values such as purchase frequency or duration of partnership, because these data would be unknown when trying to predict the potential of a client to become an acquisition. Therefore the only variables available for predicting acquisition are expenditure towards acquisition, whether the potential client is in the industry, the revenue of the client, and the number of employees of the client.

Duration variables...should the duration model include those variables as well?...I will try more in the morning



## VI - Findings


## VII - Conclusion


## Appendix


