---
title: "CustomerAcquisitionRetention2"
author: "Visha Arumugam, Michael Grogan,Sanyogita Apte"
date: "11/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(SMCRM) # CRM data
library(dplyr) # data wrangling
library(tidyr) # data wrangling
library(ggplot2) # plotting
library(survival) # survival
library(rpart) # DT
library(randomForestSRC) # RF
library(sampleSelection)
library(micEcon)


data(acquisitionRetention)
AR<-acquisitionRetention

idx.train <- sample(1:nrow(AR), size = 0.7 * nrow(AR))
train <- AR[idx.train,]
test <- AR[-idx.train,]

set.seed(123)



```



Formulas
```{r}
acq_vars<-c("acq_exp","acq_exp_sq","industry","revenue","employees")
acq_target<-"acquisition"

acq_formula<-as.formula(paste(acq_target,paste(acq_vars,collapse="+"),sep="~"))


dur_vars<-c("ret_exp","ret_exp_sq","freq","freq_sq","crossbuy","sow","IMR")

dur_target<-"duration"

dur_formula<-as.formula(paste(dur_target,paste(dur_vars,collapse="+"),sep="~"))

```




Logistic Regression
```{r}
###Logistic Acquisition prediction
acq_lm<-glm(acq_formula,train,family=binomial(link="probit"))



acq_lm_train_pred<-ifelse(predict(acq_lm,train,type="response")>0.5,1,0)

#Confusion Matrix
#table(acq_lm_train_pred,train$acquisition)
acq_lm_train_acc<-sum(acq_lm_train_pred==train$acquisition)/length(train$acquisition)



acq_lm_test_pred<-ifelse(predict(acq_lm,test,type="response")>0.5,1,0)

#Confusion Matrix
#table(acq_lm_test_pred,test$acquisition)
acq_lm_test_acc<-sum(acq_lm_test_pred==test$acquisition)/length(test$acquisition)
```

```{r}
####Logistic Duration Prediction
train$IMR<-invMillsRatio(glm(acq_formula,train,family=binomial(link="probit")))$IMR1

dur_lm<-glm(dur_formula,train,family=gaussian)

dur_lm_train_RMSE<-sqrt(mean(dur_lm$residuals^2))


test$IMR<-invMillsRatio(glm(acq_formula,test,family=binomial(link="probit")))$IMR1

dur_pred<-predict(dur_lm,test)
dur_lm_test_RMSE<-sqrt(mean((dur_pred-test$duration)^2))
```

Single Decision Tree

```{r}
acq_dt<-rpart(acq_formula,train)
dur_dt<-rpart(dur_formula,train)
```


```{r}
acq_dt_train_pred<-ifelse(predict(acq_dt,train)>0.5,1,0)
acq_dt_train_acc<-sum(acq_dt_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_dt_train_pred,train$acquisition)


acq_dt_test_pred<-ifelse(predict(acq_dt,test)>0.5,1,0)
acq_dt_test_acc<-sum(acq_dt_test_pred==test$acquisition)/length(test$acquisition)
#Confusion Matrix
#table(acq_dt_test_pred,test$acquisition)


dur_dt_train_pred<-predict(dur_dt,train)
dur_dt_train_RMSE<-sqrt(mean((dur_dt_train_pred-train$duration)^2))


dur_dt_test_pred<-predict(dur_dt,test)
dur_dt_test_RMSE<-sqrt(mean((dur_dt_test_pred-test$duration)^2))
```



Un-tuned Random Forest
```{r}
untuned_acq <- rfsrc(acq_formula,data = train)
```


```{r}
acq_untunedrf_train_pred<-ifelse(predict(untuned_acq,train)$predicted>0.5,1,0)
acq_untunedrf_train_acc<-sum(acq_untunedrf_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_untunedrf_train_pred,train$acquisition)


acq_untunedrf_test_pred<-ifelse(predict(untuned_acq,test)$predicted>0.5,1,0)
acq_untunedrf_test_acc<-sum(acq_untunedrf_test_pred==test$acquisition)/length(test$acquisition)

#Confusion Matrix
#table(acq_untunedrf_test_pred,test$acquisition)
```


```{r}
untuned_dur <- rfsrc(dur_formula,data = train)
```


```{r}
dur_untunedrf_train_pred<-predict(untuned_dur,train)$predicted
dur_untunedrf_train_RMSE<-sqrt(mean((dur_untunedrf_train_pred-train$duration)^2))
     

dur_untunedrf_test_pred<-predict(untuned_dur,test)$predicted
dur_untunedrf_test_RMSE<-sqrt(mean((dur_untunedrf_test_pred-test$duration)^2))


```





Tuned Random Forest

```{r}
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(3,8,1)
nodesize.values <- seq(4,12,2)
ntree.values <- seq(3e3,9e3,1e3)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)

# Create an empty vector to store OOB error values
oob_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {

    # Train a Random Forest model
   model <- rfsrc(acq_formula,data = train,
                            mtry = hyper_grid$mtry[i],
                            nodesize = hyper_grid$nodesize[i],
                            ntree = hyper_grid$ntree[i])  
  
                          
    # Store OOB error for the model                      
    oob_err[i] <- model$err.rate[length(model$err.rate)]
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)



tuned_acq <- rfsrc(acq_formula,data = train,
                            mtry = hyper_grid[opt_i,1],
                            nodesize = hyper_grid[opt_i,2],
                            ntree = hyper_grid[opt_i,3])
```


```{r}
acq_tunedrf_train_pred<-ifelse(predict(tuned_acq,train)$predicted>0.5,1,0)
acq_tunedrf_train_acc<-sum(acq_tunedrf_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_tunedrf_train_pred,train$acquisition)


acq_tunedrf_test_pred<-ifelse(predict(tuned_acq,test)$predicted>0.5,1,0)
acq_tunedrf_test_acc<-sum(acq_tunedrf_test_pred==test$acquisition)/length(test$acquisition)

#Confusion Matrix
#table(acq_tunedrf_test_pred,test$acquisition)

```




```{r}
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(3,8,1)
nodesize.values <- seq(4,12,2)
ntree.values <- seq(3e3,9e3,1e3)

# Create a data frame containing all combinations 
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)

# Create an empty vector to store OOB error values
oob_err <- c()

# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {

    # Train a Random Forest model
   model <- rfsrc(dur_formula,data = train,
                            mtry = hyper_grid$mtry[i],
                            nodesize = hyper_grid$nodesize[i],
                            ntree = hyper_grid$ntree[i])  
  
                          
    # Store OOB error for the model                      
    oob_err[i] <- model$err.rate[length(model$err.rate)]
}

# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)



tuned_dur <- rfsrc(dur_formula,data = train,
                            mtry = hyper_grid[opt_i,1],
                            nodesize = hyper_grid[opt_i,2],
                            ntree = hyper_grid[opt_i,3])
```


```{r}
dur_tunedrf_train_pred<-predict(tuned_dur,train)$predicted
dur_tunedrf_train_RMSE<-sqrt(mean((dur_tunedrf_train_pred-train$duration)^2))
     

dur_tunedrf_test_pred<-predict(tuned_dur,test)$predicted
dur_tunedrf_test_RMSE<-sqrt(mean((dur_tunedrf_test_pred-test$duration)^2))

```



Results

```{r}

testaccuracies<-c(acq_tunedrf_test_acc,acq_untunedrf_test_acc,acq_lm_test_acc,acq_dt_test_acc)
trainaccuracies<-c(acq_tunedrf_train_acc,acq_untunedrf_train_acc,acq_lm_train_acc,acq_dt_train_acc)
testRMSE<-c(dur_tunedrf_test_RMSE,dur_untunedrf_test_RMSE,dur_lm_test_RMSE,dur_dt_test_RMSE)
trainRMSE<-c(dur_tunedrf_train_RMSE,dur_untunedrf_train_RMSE,dur_lm_train_RMSE,dur_dt_train_RMSE)

model<-c("Tuned Random Forest","Untuned Random Forest","Linear Model","Decision Tree")

results<-data.frame(model,trainaccuracies,trainRMSE,testaccuracies,testRMSE)

results

```
```{r}
names(untuned_acq)
```



```{r}
rattle::fancyRpartPlot(dur_dt, sub = "")
rattle::fancyRpartPlot(acq_dt, sub = "")

data.frame(importance = untuned_acq$importance) %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "violet", color = "black")+
    coord_flip() +
     labs(x = "Variables", y = "Variable importance")

data.frame(importance = untuned_dur$importance) %>%
  tibble::rownames_to_column(var = "variable") %>%
  ggplot(aes(x = reorder(variable,importance), y = importance)) +
    geom_bar(stat = "identity", fill = "violet", color = "black")+
    coord_flip() +
     labs(x = "Variables", y = "Variable importance")
```

```

