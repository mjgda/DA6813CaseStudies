knitr::opts_chunk$set(echo = TRUE)
library(SMCRM) # CRM data
library(dplyr) # data wrangling
library(tidyr) # data wrangling
library(ggplot2) # plotting
library(rpart) # DT
library(randomForestSRC) # RF
library(sampleSelection)
library(PerformanceAnalytics)
data(acquisitionRetention)
AR<-acquisitionRetention
idx.train <- sample(1:nrow(AR), size = 0.7 * nrow(AR))
train <- AR[idx.train,]
test <- AR[-idx.train,]
set.seed(123)
chart.Correlation(AR, histogram = TRUE, pch=20)
set.seed(123)
AR_forest_dur = rfsrc(duration~acq_exp +
ret_exp+
freq+
crossbuy+
sow+
profit+
industry +
revenue +
employees,
data= AR,
importance= TRUE,
ntree=1000)
data.frame(importance= AR_forest_dur$importance+100) %>%
#log() %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x=reorder(variable,importance),y=importance))+
geom_bar(stat = "identity",fill="orange",color="black",width = 0.5)+
coord_flip()+
labs(x="variables",y="log transformed Variable importance")
AR_forest_acq = rfsrc(acquisition~acq_exp +
ret_exp+
freq+
crossbuy+
sow+
duration+
profit+
industry +
revenue +
employees,
data= AR,
importance= TRUE,
ntree=1000)
data.frame(importance= AR_forest_acq$importance+100) %>%
#log() %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x=reorder(variable,importance),y=importance))+
geom_bar(stat = "identity",fill="orange",color="black",width = 0.5)+
coord_flip()+
labs(x="variables",y="log transformed Varaible importance")
dur_vars
glm(dur_full_formula,AR,family=gaussian)
summary(glm(dur_full_formula,AR,family=gaussian))
summary(glm(dur_full_formula,AR,family=gaussian))
knitr::opts_chunk$set(echo = TRUE)
library(SMCRM) # CRM data
library(dplyr) # data wrangling
library(tidyr) # data wrangling
library(ggplot2) # plotting
library(rpart) # DT
library(randomForestSRC) # RF
library(sampleSelection)
library(PerformanceAnalytics)
data(acquisitionRetention)
AR<-acquisitionRetention
idx.train <- sample(1:nrow(AR), size = 0.7 * nrow(AR))
train <- AR[idx.train,]
test <- AR[-idx.train,]
set.seed(123)
chart.Correlation(AR, histogram = TRUE, pch=20)
set.seed(123)
AR_forest_dur = rfsrc(duration~acq_exp +
ret_exp+
freq+
crossbuy+
sow+
profit+
industry +
revenue +
employees,
data= AR,
importance= TRUE,
ntree=1000)
data.frame(importance= AR_forest_dur$importance+100) %>%
#log() %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x=reorder(variable,importance),y=importance))+
geom_bar(stat = "identity",fill="orange",color="black",width = 0.5)+
coord_flip()+
labs(x="variables",y="log transformed Variable importance")
AR_forest_acq = rfsrc(acquisition~acq_exp +
ret_exp+
freq+
crossbuy+
sow+
duration+
profit+
industry +
revenue +
employees,
data= AR,
importance= TRUE,
ntree=1000)
data.frame(importance= AR_forest_acq$importance+100) %>%
#log() %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x=reorder(variable,importance),y=importance))+
geom_bar(stat = "identity",fill="orange",color="black",width = 0.5)+
coord_flip()+
labs(x="variables",y="log transformed Varaible importance")
acq_vars<-c("acq_exp","acq_exp_sq","industry","revenue","employees")
acq_target<-"acquisition"
acq_formula<-as.formula(paste(acq_target,paste(acq_vars,collapse="+"),sep="~"))
dur_vars<-c("ret_exp","ret_exp_sq","freq","freq_sq","crossbuy","sow","IMR")
dur_target<-"duration"
dur_formula<-as.formula(paste(dur_target,paste(dur_vars,collapse="+"),sep="~"))
dur_full<-c("ret_exp","ret_exp_sq","freq","freq_sq","crossbuy","sow","acq_exp","acq_exp_sq","industry","revenue","employees")
dur_full_formula<-as.formula(paste(dur_target,paste(dur_full,collapse="+"),sep="~"))
untuned_full_dur<-rfsrc(dur_full_formula,data = AR,importance = TRUE)
#Logistic Regression
###Logistic Acquisition prediction
acq_lm<-glm(acq_formula,train,family=binomial(link="probit"))
acq_lm_train_pred<-ifelse(predict(acq_lm,train,type="response")>0.5,1,0)
#Confusion Matrix
#table(acq_lm_train_pred,train$acquisition)
acq_lm_train_acc<-sum(acq_lm_train_pred==train$acquisition)/length(train$acquisition)
acq_lm_test_pred<-ifelse(predict(acq_lm,test,type="response")>0.5,1,0)
#Confusion Matrix
#table(acq_lm_test_pred,test$acquisition)
acq_lm_test_acc<-sum(acq_lm_test_pred==test$acquisition)/length(test$acquisition)
####Logistic Duration Prediction
train$IMR<-invMillsRatio(glm(acq_formula,train,family=binomial(link="probit")))$IMR1
dur_lm<-glm(dur_formula,train,family=gaussian)
dur_lm_train_RMSE<-sqrt(mean(dur_lm$residuals^2))
test$IMR<-invMillsRatio(glm(acq_formula,test,family=binomial(link="probit")))$IMR1
dur_pred<-predict(dur_lm,test)
dur_lm_test_RMSE<-sqrt(mean((dur_pred-test$duration)^2))
####Logistic Duration Prediction All variables
dur_flm<-glm(dur_full_formula,train,family=gaussian)
dur_flm_train_RMSE<-sqrt(mean(dur_flm$residuals^2))
dur_pred<-predict(dur_flm,test)
dur_flm_test_RMSE<-sqrt(mean((dur_pred-test$duration)^2))
#Single Decision Tree
acq_dt<-rpart(acq_formula,train)
dur_dt<-rpart(dur_formula,train)
acq_dt_train_pred<-ifelse(predict(acq_dt,train)>0.5,1,0)
acq_dt_train_acc<-sum(acq_dt_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_dt_train_pred,train$acquisition)
acq_dt_test_pred<-ifelse(predict(acq_dt,test)>0.5,1,0)
acq_dt_test_acc<-sum(acq_dt_test_pred==test$acquisition)/length(test$acquisition)
#Confusion Matrix
#table(acq_dt_test_pred,test$acquisition)
dur_dt_train_pred<-predict(dur_dt,train)
dur_dt_train_RMSE<-sqrt(mean((dur_dt_train_pred-train$duration)^2))
dur_dt_test_pred<-predict(dur_dt,test)
dur_dt_test_RMSE<-sqrt(mean((dur_dt_test_pred-test$duration)^2))
#Un-tuned Random Forest
untuned_acq <- rfsrc(acq_formula,data = train,importance = TRUE)
acq_untunedrf_train_pred<-ifelse(predict(untuned_acq,train)$predicted>0.5,1,0)
acq_untunedrf_train_acc<-sum(acq_untunedrf_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_untunedrf_train_pred,train$acquisition)
acq_untunedrf_test_pred<-ifelse(predict(untuned_acq,test)$predicted>0.5,1,0)
acq_untunedrf_test_acc<-sum(acq_untunedrf_test_pred==test$acquisition)/length(test$acquisition)
#Confusion Matrix
#table(acq_untunedrf_test_pred,test$acquisition)
untuned_dur <- rfsrc(dur_formula,data = train,importance = TRUE)
dur_untunedrf_train_pred<-predict(untuned_dur,train)$predicted
dur_untunedrf_train_RMSE<-sqrt(mean((dur_untunedrf_train_pred-train$duration)^2))
dur_untunedrf_test_pred<-predict(untuned_dur,test)$predicted
dur_untunedrf_test_RMSE<-sqrt(mean((dur_untunedrf_test_pred-test$duration)^2))
#Tuned Random Forest
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(3,8,1)
nodesize.values <- seq(4,12,2)
ntree.values <- seq(3e3,9e3,1e3)
# Create a data frame containing all combinations
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)
# Create an empty vector to store OOB error values
oob_err <- c()
# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {
# Train a Random Forest model
model <- rfsrc(acq_formula,data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i],
ntree = hyper_grid$ntree[i])
# Store OOB error for the model
oob_err[i] <- model$err.rate[length(model$err.rate)]
}
# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)
tuned_acq <- rfsrc(acq_formula,data = train,
mtry = hyper_grid[opt_i,1],
nodesize = hyper_grid[opt_i,2],
ntree = hyper_grid[opt_i,3])
acq_tunedrf_train_pred<-ifelse(predict(tuned_acq,train)$predicted>0.5,1,0)
acq_tunedrf_train_acc<-sum(acq_tunedrf_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_tunedrf_train_pred,train$acquisition)
acq_tunedrf_test_pred<-ifelse(predict(tuned_acq,test)$predicted>0.5,1,0)
acq_tunedrf_test_acc<-sum(acq_tunedrf_test_pred==test$acquisition)/length(test$acquisition)
#Confusion Matrix
#table(acq_tunedrf_test_pred,test$acquisition)
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(3,8,1)
nodesize.values <- seq(4,12,2)
ntree.values <- seq(3e3,9e3,1e3)
# Create a data frame containing all combinations
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)
# Create an empty vector to store OOB error values
oob_err <- c()
# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {
# Train a Random Forest model
model <- rfsrc(dur_formula,data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i],
ntree = hyper_grid$ntree[i])
# Store OOB error for the model
oob_err[i] <- model$err.rate[length(model$err.rate)]
}
# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)
tuned_dur <- rfsrc(dur_formula,data = train,
mtry = hyper_grid[opt_i,1],
nodesize = hyper_grid[opt_i,2],
ntree = hyper_grid[opt_i,3])
dur_tunedrf_train_pred<-predict(tuned_dur,train)$predicted
dur_tunedrf_train_RMSE<-sqrt(mean((dur_tunedrf_train_pred-train$duration)^2))
dur_tunedrf_test_pred<-predict(tuned_dur,test)$predicted
dur_tunedrf_test_RMSE<-sqrt(mean((dur_tunedrf_test_pred-test$duration)^2))
data.frame(importance = untuned_acq$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "violet", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")
data.frame(importance = untuned_dur$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "violet", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")
for(i in acq_vars){
sequence_<-seq(quantile(AR[[i]])[[2]],quantile(AR[[i]])[[4]],(quantile(AR[[i]])[[2]]-quantile(AR[[i]])[[4]])/-30)
means.exp<-partial(untuned_acq,partial.xvar = i,
partial.values = sequence_)$regrOutput$acquisition %>% colMeans()
marginal.effect.df <-
data.frame(pred.acquisition = means.exp, sequence_ = sequence_)
print(
ggplot(marginal.effect.df, aes(x = sequence_, y = pred.acquisition)) +
geom_point(shape = 20, color = "purple", size = 2, stroke = 1.5)+
geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), se = FALSE, color = "black")+
labs(x = i, y = "Predicted acquisition")
)
}
for(i in dur_vars[-7]){
sequence_<-seq(quantile(AR[[i]])[[2]],quantile(AR[[i]])[[4]],(quantile(AR[[i]])[[2]]-quantile(AR[[i]])[[4]])/-30)
means.exp<-partial(untuned_dur,partial.xvar = i,
partial.values = sequence_)$regrOutput$duration %>% colMeans()
marginal.effect.df <-
data.frame(pred.duration = means.exp, sequence_ = sequence_)
print(
ggplot(marginal.effect.df, aes(x = sequence_, y = pred.duration)) +
geom_point(shape = 20, color = "purple", size = 2, stroke = 1.5)+
geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), se = FALSE, color = "black")+
labs(x = i, y = "Predicted duration")
)
}
testaccuracies<-c(acq_tunedrf_test_acc,acq_untunedrf_test_acc,acq_lm_test_acc,acq_lm_test_acc,acq_dt_test_acc)
trainaccuracies<-c(acq_tunedrf_train_acc,acq_untunedrf_train_acc,acq_lm_train_acc,acq_lm_train_acc,acq_dt_train_acc)
testRMSE<-c(dur_tunedrf_test_RMSE,dur_untunedrf_test_RMSE,dur_flm_test_RMSE,dur_lm_test_RMSE,dur_dt_test_RMSE)
trainRMSE<-c(dur_tunedrf_train_RMSE,dur_untunedrf_train_RMSE,dur_flm_train_RMSE,dur_lm_train_RMSE,dur_dt_train_RMSE)
model<-c("Tuned Random Forest","Untuned Random Forest","Full Linear","Linear Model","Decision Tree")
results<-data.frame(model,trainaccuracies,trainRMSE,testaccuracies,testRMSE)
results
rattle::fancyRpartPlot(dur_dt, sub = "")
rattle::fancyRpartPlot(acq_dt, sub = "")
data.frame(importance = untuned_acq$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "violet", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")
data.frame(importance = untuned_full_dur$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "violet", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")
#Confusion Matrix
table(acq_lm_test_pred,test$acquisition)
#Confusion Matrix
table(acq_tunedrf_test_pred,test$acquisition)
?table
#Confusion Matrix
table(acq_lm_test_pred,test$acquisition,dnn=c("Linear","Actuals"))
#Confusion Matrix
table(acq_tunedrf_test_pred,test$acquisition,dnn=c("Linear","Actuals"))
#Confusion Matrix
table(acq_lm_test_pred,test$acquisition,dnn=c("Linear","Actuals"))
#Confusion Matrix
table(acq_tunedrf_test_pred,test$acquisition,dnn=c("RF","Actuals"))
#Confusion Matrix
table(acq_lm_test_pred,test$acquisition,dnn=c("LM","Actuals"))
#Confusion Matrix
table(acq_tunedrf_test_pred,test$acquisition,dnn=c("RF","Actuals"))
#Confusion Matrix
table(acq_lm_test_pred,test$acquisition,dnn=c("LM","Actuals"))
#Confusion Matrix
table(acq_untunedrf_test_pred,test$acquisition,dnn=c("RF","Actuals"))
#Confusion Matrix
table(acq_lm_test_pred,test$acquisition,dnn=c("LM","Actuals"))
#Confusion Matrix
table(acq_tunedrf_test_pred,test$acquisition,dnn=c("RF","Actuals"))
knitr::opts_chunk$set(echo = TRUE)
library(SMCRM) # CRM data
library(dplyr) # data wrangling
library(tidyr) # data wrangling
library(ggplot2) # plotting
library(rpart) # DT
library(randomForestSRC) # RF
library(sampleSelection)
library(PerformanceAnalytics)
data(acquisitionRetention)
AR<-acquisitionRetention
idx.train <- sample(1:nrow(AR), size = 0.7 * nrow(AR))
train <- AR[idx.train,]
test <- AR[-idx.train,]
set.seed(123)
acq_vars<-c("acq_exp","acq_exp_sq","industry","revenue","employees")
acq_target<-"acquisition"
acq_formula<-as.formula(paste(acq_target,paste(acq_vars,collapse="+"),sep="~"))
dur_vars<-c("ret_exp","ret_exp_sq","freq","freq_sq","crossbuy","sow","IMR")
dur_target<-"duration"
dur_formula<-as.formula(paste(dur_target,paste(dur_vars,collapse="+"),sep="~"))
dur_full<-c("ret_exp","ret_exp_sq","freq","freq_sq","crossbuy","sow","acq_exp","acq_exp_sq","industry","revenue","employees")
dur_full_formula<-as.formula(paste(dur_target,paste(dur_full,collapse="+"),sep="~"))
untuned_full_dur<-rfsrc(dur_full_formula,data = AR,importance = TRUE)
#Logistic Regression
###Logistic Acquisition prediction
acq_lm<-glm(acq_formula,train,family=binomial(link="probit"))
acq_lm_train_pred<-ifelse(predict(acq_lm,train,type="response")>0.5,1,0)
#Confusion Matrix
#table(acq_lm_train_pred,train$acquisition)
acq_lm_train_acc<-sum(acq_lm_train_pred==train$acquisition)/length(train$acquisition)
acq_lm_test_pred<-ifelse(predict(acq_lm,test,type="response")>0.5,1,0)
#Confusion Matrix
#table(acq_lm_test_pred,test$acquisition)
acq_lm_test_acc<-sum(acq_lm_test_pred==test$acquisition)/length(test$acquisition)
####Logistic Duration Prediction
train$IMR<-invMillsRatio(glm(acq_formula,train,family=binomial(link="probit")))$IMR1
dur_lm<-glm(dur_formula,train,family=gaussian)
dur_lm_train_RMSE<-sqrt(mean(dur_lm$residuals^2))
test$IMR<-invMillsRatio(glm(acq_formula,test,family=binomial(link="probit")))$IMR1
dur_pred<-predict(dur_lm,test)
dur_lm_test_RMSE<-sqrt(mean((dur_pred-test$duration)^2))
####Logistic Duration Prediction All variables
dur_flm<-glm(dur_full_formula,train,family=gaussian)
dur_flm_train_RMSE<-sqrt(mean(dur_flm$residuals^2))
dur_pred<-predict(dur_flm,test)
dur_flm_test_RMSE<-sqrt(mean((dur_pred-test$duration)^2))
#Single Decision Tree
acq_dt<-rpart(acq_formula,train)
dur_dt<-rpart(dur_formula,train)
acq_dt_train_pred<-ifelse(predict(acq_dt,train)>0.5,1,0)
acq_dt_train_acc<-sum(acq_dt_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_dt_train_pred,train$acquisition)
acq_dt_test_pred<-ifelse(predict(acq_dt,test)>0.5,1,0)
acq_dt_test_acc<-sum(acq_dt_test_pred==test$acquisition)/length(test$acquisition)
#Confusion Matrix
#table(acq_dt_test_pred,test$acquisition)
dur_dt_train_pred<-predict(dur_dt,train)
dur_dt_train_RMSE<-sqrt(mean((dur_dt_train_pred-train$duration)^2))
dur_dt_test_pred<-predict(dur_dt,test)
dur_dt_test_RMSE<-sqrt(mean((dur_dt_test_pred-test$duration)^2))
#Un-tuned Random Forest
untuned_acq <- rfsrc(acq_formula,data = train,importance = TRUE)
acq_untunedrf_train_pred<-ifelse(predict(untuned_acq,train)$predicted>0.5,1,0)
acq_untunedrf_train_acc<-sum(acq_untunedrf_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_untunedrf_train_pred,train$acquisition)
acq_untunedrf_test_pred<-ifelse(predict(untuned_acq,test)$predicted>0.5,1,0)
acq_untunedrf_test_acc<-sum(acq_untunedrf_test_pred==test$acquisition)/length(test$acquisition)
#Confusion Matrix
#table(acq_untunedrf_test_pred,test$acquisition)
untuned_dur <- rfsrc(dur_formula,data = train,importance = TRUE)
dur_untunedrf_train_pred<-predict(untuned_dur,train)$predicted
dur_untunedrf_train_RMSE<-sqrt(mean((dur_untunedrf_train_pred-train$duration)^2))
dur_untunedrf_test_pred<-predict(untuned_dur,test)$predicted
dur_untunedrf_test_RMSE<-sqrt(mean((dur_untunedrf_test_pred-test$duration)^2))
#Tuned Random Forest
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(3,8,1)
nodesize.values <- seq(4,12,2)
ntree.values <- seq(3e3,9e3,1e3)
# Create a data frame containing all combinations
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)
# Create an empty vector to store OOB error values
oob_err <- c()
# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {
# Train a Random Forest model
model <- rfsrc(acq_formula,data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i],
ntree = hyper_grid$ntree[i])
# Store OOB error for the model
oob_err[i] <- model$err.rate[length(model$err.rate)]
}
# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)
tuned_acq <- rfsrc(acq_formula,data = train,
mtry = hyper_grid[opt_i,1],
nodesize = hyper_grid[opt_i,2],
ntree = hyper_grid[opt_i,3])
acq_tunedrf_train_pred<-ifelse(predict(tuned_acq,train)$predicted>0.5,1,0)
acq_tunedrf_train_acc<-sum(acq_tunedrf_train_pred==train$acquisition)/length(train$acquisition)
#Confusion Matrix
#table(acq_tunedrf_train_pred,train$acquisition)
acq_tunedrf_test_pred<-ifelse(predict(tuned_acq,test)$predicted>0.5,1,0)
acq_tunedrf_test_acc<-sum(acq_tunedrf_test_pred==test$acquisition)/length(test$acquisition)
#Confusion Matrix
#table(acq_tunedrf_test_pred,test$acquisition)
# Establish a list of possible values for hyper-parameters
mtry.values <- seq(3,8,1)
nodesize.values <- seq(4,12,2)
ntree.values <- seq(3e3,9e3,1e3)
# Create a data frame containing all combinations
hyper_grid <- expand.grid(mtry = mtry.values, nodesize = nodesize.values, ntree = ntree.values)
# Create an empty vector to store OOB error values
oob_err <- c()
# Write a loop over the rows of hyper_grid to train the grid of models
for (i in 1:nrow(hyper_grid)) {
# Train a Random Forest model
model <- rfsrc(dur_formula,data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i],
ntree = hyper_grid$ntree[i])
# Store OOB error for the model
oob_err[i] <- model$err.rate[length(model$err.rate)]
}
# Identify optimal set of hyperparmeters based on OOB error
opt_i <- which.min(oob_err)
tuned_dur <- rfsrc(dur_formula,data = train,
mtry = hyper_grid[opt_i,1],
nodesize = hyper_grid[opt_i,2],
ntree = hyper_grid[opt_i,3])
dur_tunedrf_train_pred<-predict(tuned_dur,train)$predicted
dur_tunedrf_train_RMSE<-sqrt(mean((dur_tunedrf_train_pred-train$duration)^2))
dur_tunedrf_test_pred<-predict(tuned_dur,test)$predicted
dur_tunedrf_test_RMSE<-sqrt(mean((dur_tunedrf_test_pred-test$duration)^2))
data.frame(importance = untuned_acq$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "violet", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")
data.frame(importance = untuned_full_dur$importance) %>%
tibble::rownames_to_column(var = "variable") %>%
ggplot(aes(x = reorder(variable,importance), y = importance)) +
geom_bar(stat = "identity", fill = "violet", color = "black")+
coord_flip() +
labs(x = "Variables", y = "Variable importance")
for(i in acq_vars){
sequence_<-seq(quantile(AR[[i]])[[2]],quantile(AR[[i]])[[4]],(quantile(AR[[i]])[[2]]-quantile(AR[[i]])[[4]])/-30)
means.exp<-partial(untuned_acq,partial.xvar = i,
partial.values = sequence_)$regrOutput$acquisition %>% colMeans()
marginal.effect.df <-
data.frame(pred.acquisition = means.exp, sequence_ = sequence_)
print(
ggplot(marginal.effect.df, aes(x = sequence_, y = pred.acquisition)) +
geom_point(shape = 20, color = "purple", size = 2, stroke = 1.5)+
geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), se = FALSE, color = "black")+
labs(x = i, y = "Predicted acquisition")
)
}
for(i in dur_vars[-7]){
sequence_<-seq(quantile(AR[[i]])[[2]],quantile(AR[[i]])[[4]],(quantile(AR[[i]])[[2]]-quantile(AR[[i]])[[4]])/-30)
means.exp<-partial(untuned_dur,partial.xvar = i,
partial.values = sequence_)$regrOutput$duration %>% colMeans()
marginal.effect.df <-
data.frame(pred.duration = means.exp, sequence_ = sequence_)
print(
ggplot(marginal.effect.df, aes(x = sequence_, y = pred.duration)) +
geom_point(shape = 20, color = "purple", size = 2, stroke = 1.5)+
geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), se = FALSE, color = "black")+
labs(x = i, y = "Predicted duration")
)
}
testaccuracies<-c(acq_tunedrf_test_acc,acq_untunedrf_test_acc,acq_lm_test_acc,acq_lm_test_acc,acq_dt_test_acc)
trainaccuracies<-c(acq_tunedrf_train_acc,acq_untunedrf_train_acc,acq_lm_train_acc,acq_lm_train_acc,acq_dt_train_acc)
testRMSE<-c(dur_tunedrf_test_RMSE,dur_untunedrf_test_RMSE,dur_flm_test_RMSE,dur_lm_test_RMSE,dur_dt_test_RMSE)
trainRMSE<-c(dur_tunedrf_train_RMSE,dur_untunedrf_train_RMSE,dur_flm_train_RMSE,dur_lm_train_RMSE,dur_dt_train_RMSE)
model<-c("Tuned Random Forest","Untuned Random Forest","Full Linear","Linear Model","Decision Tree")
results<-data.frame(model,trainaccuracies,trainRMSE,testaccuracies,testRMSE)
results
#Confusion Matrix
table(acq_lm_test_pred,test$acquisition,dnn=c("LM","Actuals"))
#Confusion Matrix
table(acq_tunedrf_test_pred,test$acquisition,dnn=c("RF","Actuals"))
rattle::fancyRpartPlot(dur_dt, sub = "")
rattle::fancyRpartPlot(acq_dt, sub = "")
